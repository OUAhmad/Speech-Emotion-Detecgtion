{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Emodb CNN and LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "7n0-hpj24Ykm",
        "isbMlo3Q4jcx"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mknthjns4bdE",
        "colab_type": "text"
      },
      "source": [
        "##Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeQCSGCn8FuA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2ae3a2a7-a455-4885-9ba4-70c7453dd883"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import librosa\n",
        "import librosa.display\n",
        "from keras.models import Model,Sequential\n",
        "from keras import optimizers\n",
        "from keras.layers import Input,Conv1D,BatchNormalization,MaxPooling1D,LSTM,Dense,Activation,Layer,Conv2D,MaxPooling2D,Flatten,Reshape\n",
        "from tensorflow.keras import regularizers\n",
        "from keras.regularizers import l2\n",
        "from keras.utils import to_categorical\n",
        "import keras.backend as K\n",
        "import argparse\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7n0-hpj24Ykm",
        "colab_type": "text"
      },
      "source": [
        "##Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeYCpyGs9DcB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir Emodb_dataset\n",
        "!unzip \"./EmoDB.zip\" -d Emodb_dataset; # Dataset Link: http://emodb.bilderbar.info/index-1280.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaXZQDRWsK2Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "588dba2a-a85a-4541-aa9d-d958c1ad7989"
      },
      "source": [
        "# use raw time-domain speech signal as input to cnn for SER\n",
        "\n",
        "datapath = 'Emodb_dataset/wav'\n",
        "classes = np.array(['W','L','E','A','F','T','N']) # 7 classes\n",
        "\n",
        "Seconds_per_sample = 8 # The sample size in seconds\n",
        "Padded_sample = True # Whether to take samples which are less than the required length\n",
        "fs = 16000 # Sampling Frequency of Input data\n",
        "seg_len = int((Seconds_per_sample)*16000) # signal split length (in samples) in time domain\n",
        "seg_ov = int(seg_len*0.5) # 50% overlap\n",
        "\n",
        "def normalize(s):\n",
        "# RMS normalization\n",
        "\tnew_s = s/np.sqrt(np.sum(np.square((np.abs(s))))/len(s))\n",
        "\treturn new_s\n",
        "\n",
        "def countclasses(fnames):\n",
        "\tdict = {classes[0]:0,classes[1]:0,classes[2]:0,classes[3]:0,classes[4]:0,classes[5]:0,classes[6]:0}\n",
        "\tfor name in fnames:\n",
        "\t\tif name[5] in classes:\n",
        "\t\t\tdict[name[5]]+=1\n",
        "\treturn dict\n",
        "\n",
        "def data1d(path):\n",
        "\n",
        "\tfnames = os.listdir(datapath)\n",
        "\tdict = countclasses(fnames)\n",
        "\tprint('Total Data',dict)\n",
        "\tnum_cl = len(classes)\n",
        "\ttrain_dict = {classes[0]:0,classes[1]:0,classes[2]:0,classes[3]:0,classes[4]:0,classes[5]:0,classes[6]:0}\n",
        "\ttest_dict = {classes[0]:0,classes[1]:0,classes[2]:0,classes[3]:0,classes[4]:0,classes[5]:0,classes[6]:0}\n",
        "\tval_dict = {classes[0]:0,classes[1]:0,classes[2]:0,classes[3]:0,classes[4]:0,classes[5]:0,classes[6]:0}\n",
        "\n",
        "\tfor i in range(num_cl):\n",
        "\t\tcname =  list(dict.keys())[i]\n",
        "\t\tcnum = dict[cname]\n",
        "\t\tt = round(0.8*cnum)\n",
        "\t\ttest_dict[cname] = int(cnum - t)\n",
        "\t\tval_dict[cname] = int(round(0.2*t))\n",
        "\t\ttrain_dict[cname] = int(t - val_dict[cname])\n",
        "\t\tprint('Class:',cname,'train:',train_dict[cname],'val:',val_dict[cname],'test:',test_dict[cname])\n",
        "\t\t\n",
        "\tx_train = []\n",
        "\ty_train = []\n",
        "\tx_test = []\n",
        "\ty_test = []\n",
        "\tx_val = []\n",
        "\ty_val = []\n",
        "\n",
        "\tcount = {classes[0]:0,classes[1]:0,classes[2]:0,classes[3]:0,classes[4]:0,classes[5]:0,classes[6]:0}\n",
        "\tloop = 1\n",
        "\tfor name in fnames:\n",
        "\t\t\n",
        "\t\tif name[5] in classes:\n",
        "\t\t\tsig,fs = librosa.load(datapath+'/'+name, sr=16000)\n",
        "\t\t\tif loop > 0:\n",
        "\t\t\t\t\tloop = -1\n",
        "\t\t\t\t\tprint(\"First File: \",name)\n",
        "\t\t\t\t\tprint(\"Audio Signals approximate Lengths: \",sig.shape)\n",
        "\t\t\t\n",
        "\t\t\t# normalize signal\n",
        "\t\t\tdata = normalize(sig)\n",
        "\t\t\tif(len(data) < seg_len):\n",
        "\t\t\t\tpad_len = int(seg_len - len(data))\n",
        "\t\t\t\tpad_rem = int(pad_len % 2)\n",
        "\t\t\t\tpad_len /= 2\n",
        "\t\t\t\tsignal = np.pad(data,(int(pad_len), int(pad_len+pad_rem)),'constant',constant_values=0)\n",
        "\t\t\telif(len(data) > seg_len):\n",
        "\t\t\t\tsignal = []\n",
        "\t\t\t\tend = seg_len\n",
        "\t\t\t\tst = 0\n",
        "\t\t\t\twhile(end < len(data)):\n",
        "\t\t\t\t\tsignal.append(data[st:end])\n",
        "\t\t\t\t\tst = st + seg_ov\n",
        "\t\t\t\t\tend = st + seg_len\n",
        "\t\t\t\tsignal = np.array(signal)\n",
        "\t\t\t\tif(end >= len(data)):\n",
        "\t\t\t\t\tnum_zeros = int(end-len(data))\n",
        "\t\t\t\t\tif(num_zeros > 0):\n",
        "\t\t\t\t\t\tn1 = np.array(data[st:end])\n",
        "\t\t\t\t\t\tn2 = np.zeros([num_zeros])\n",
        "\t\t\t\t\t\ts = np.concatenate([n1,n2],0)\n",
        "\t\t\t\t\telse:\n",
        "\t\t\t\t\t\ts = np.array(data[int(st):int(end)])\n",
        "\t\t\t\tsignal = np.vstack([signal,s])\n",
        "\t\t\telse:\n",
        "\t\t\t\tsignal = data\n",
        "\n",
        "\t\t\tif(count[name[5]] < train_dict[name[5]]):\n",
        "\t\t\t\tif(signal.ndim>1):\n",
        "\t\t\t\t\tfor i in range(signal.shape[0]):\t\t\t\t\t\t\n",
        "\t\t\t\t\t\tx_train.append(signal[i])\n",
        "\t\t\t\t\t\ty_train.append(name[5])\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tx_train.append(signal)\n",
        "\t\t\t\t\ty_train.append(name[5])\n",
        "\t\t\telse:\n",
        "\t\t\t\tif((count[name[5]]-train_dict[name[5]]) < val_dict[name[5]]):\n",
        "\t\t\t\t\tif(signal.ndim>1):\n",
        "\t\t\t\t\t\tfor i in range(signal.shape[0]):\t\t\t\t\t\t\t\n",
        "\t\t\t\t\t\t\tx_val.append(signal[i])\n",
        "\t\t\t\t\t\t\ty_val.append(name[5])\n",
        "\t\t\t\t\telse:\n",
        "\t\t\t\t\t\tx_val.append(signal)\n",
        "\t\t\t\t\t\ty_val.append(name[5])\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tif(signal.ndim>1):\n",
        "\t\t\t\t\t\tfor i in range(signal.shape[0]):\n",
        "\t\t\t\t\t\t\tx_test.append(signal[i])\n",
        "\t\t\t\t\t\t\ty_test.append(name[5])\n",
        "\t\t\t\t\telse:\n",
        "\t\t\t\t\t\tx_test.append(signal)\n",
        "\t\t\t\t\t\ty_test.append(name[5])\n",
        "\t\t\tcount[name[5]]+=1\n",
        "\treturn np.float32(x_train),y_train,np.float32(x_test),y_test,np.float32(x_val),y_val\n",
        "\n",
        "def string2num(y):\n",
        "\ty1 = []\n",
        "\tfor i in y:\n",
        "\t\tif(i == classes[0]):\n",
        "\t\t\ty1.append(0)\n",
        "\t\telif(i == classes[1]):\n",
        "\t\t\ty1.append(1)\n",
        "\t\telif(i == classes[2]):\n",
        "\t\t\ty1.append(2)\n",
        "\t\telif(i == classes[3]):\n",
        "\t\t\ty1.append(3)\n",
        "\t\telif(i == classes[4]):\n",
        "\t\t\ty1.append(4)\n",
        "\t\telif(i == classes[5]):\n",
        "\t\t\ty1.append(5)\n",
        "\t\telse:\n",
        "\t\t\ty1.append(6)\n",
        "\ty1 = np.float32(np.array(y1))\n",
        "\treturn y1\n",
        "\n",
        "def load_data():\n",
        "\tx_tr,y_tr,x_t,y_t,x_v,y_v = data1d(datapath)\n",
        "\ty_tr = string2num(y_tr)\n",
        "\ty_t = string2num(y_t)\n",
        "\ty_v = string2num(y_v)\n",
        "\treturn x_tr, y_tr, x_t, y_t, x_v, y_v\n",
        "\n",
        "xd_tr,yd_tr,xd_t,yd_t,xd_val,yd_val = load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Data {'W': 127, 'L': 81, 'E': 46, 'A': 69, 'F': 71, 'T': 62, 'N': 79}\n",
            "Class: W train: 82 val: 20 test: 25\n",
            "Class: L train: 52 val: 13 test: 16\n",
            "Class: E train: 30 val: 7 test: 9\n",
            "Class: A train: 44 val: 11 test: 14\n",
            "Class: F train: 46 val: 11 test: 14\n",
            "Class: T train: 40 val: 10 test: 12\n",
            "Class: N train: 50 val: 13 test: 16\n",
            "First File:  12b02Wd.wav\n",
            "Audio Signals approximate Lengths:  (42398,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isbMlo3Q4jcx",
        "colab_type": "text"
      },
      "source": [
        "## 1D CNN and LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-LvZXPLstop",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1D cnn for SER\n",
        "\n",
        "def emo1d(input_shape, num_classes,args):\n",
        "\t\n",
        "\tmodel = Sequential(name='Emo1D')\n",
        "\t\n",
        "\t# LFLB1\n",
        "\tmodel.add(Conv1D(filters = 64,kernel_size = (3),strides=1,padding='same',data_format='channels_last',input_shape=input_shape, kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\t\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(Activation('elu'))\n",
        "\tmodel.add(MaxPooling1D(pool_size = 4, strides = 4))\n",
        "\n",
        "\t#LFLB2\n",
        "\tmodel.add(Conv1D(filters=64, kernel_size = 3, strides=1,padding='same', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(Activation('elu'))\n",
        "\tmodel.add(MaxPooling1D(pool_size = 4, strides = 4))\n",
        "\n",
        "\t#LFLB3\n",
        "\tmodel.add(Conv1D(filters=128, kernel_size = 3, strides=1,padding='same', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(Activation('elu'))\n",
        "\tmodel.add(MaxPooling1D(pool_size = 4, strides = 4))\n",
        "\n",
        "\t#LFLB4\n",
        "\tmodel.add(Conv1D(filters=128, kernel_size = 3, strides=1,padding='same', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(Activation('elu'))\n",
        "\tmodel.add(MaxPooling1D(pool_size = 4, strides = 4))\n",
        "\n",
        "\t#LSTM\n",
        "\tmodel.add(LSTM(units=args.num_fc, kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.01))) \n",
        "\t\t\n",
        "\t#FC\n",
        "\tmodel.add(Dense(units=100,activation='relu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
        "\n",
        "\tmodel.add(Dense(units=num_classes,activation='softmax'))\n",
        "\n",
        "\n",
        "\t#Model compilation\t\n",
        "\topt = optimizers.SGD(lr = args.learning_rate, decay=args.decay, momentum=args.momentum, nesterov=True)\n",
        "\tmodel.compile(optimizer=opt,loss='categorical_crossentropy',metrics=['categorical_accuracy'])\n",
        "\t\n",
        "\treturn model\n",
        "\n",
        "def train(model,x_tr,y_tr,x_val,y_val,args):\n",
        "\t\n",
        "\tes = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=8)\n",
        "\tmc = ModelCheckpoint('best_model_1D_CNN.h5', monitor='val_categorical_accuracy', mode='max', verbose=1, save_best_only=True)\n",
        "\thistory = model.fit(x_tr,y_tr,epochs=args.num_epochs,batch_size=args.batch_size,validation_data=(x_val,y_val),callbacks=[es, mc])\n",
        "\treturn model\n",
        "\n",
        "def test(model,x_t,y_t):\n",
        "\n",
        "\tsaved_model = load_model('best_model_1D_CNN.h5')\n",
        "\tscore = saved_model.evaluate(x_t,y_t,batch_size=20)\n",
        "\tprint(score)\n",
        "\treturn score\n",
        "\n",
        "def loadData1d(x_tr,y_tr,x_t,y_t,x_val,y_val):\n",
        "\n",
        "\tx_tr = x_tr.reshape(-1,x_tr.shape[1],1)\n",
        "\tx_t = x_t.reshape(-1,x_t.shape[1],1)\n",
        "\tx_val = x_val.reshape(-1,x_val.shape[1],1)\n",
        "\ty_tr = to_categorical(y_tr)\n",
        "\ty_t = to_categorical(y_t)\n",
        "\ty_val = to_categorical(y_val)\n",
        "\treturn x_tr,y_tr,x_t,y_t,x_val,y_val\n",
        "\n",
        "class arguments(object):        \n",
        "\t\tdef __init__(self):\n",
        "\t\t\t\tself.num_fc = 256\n",
        "\t\t\t\tself.batch_size = 64\n",
        "\t\t\t\tself.num_epochs = 200 #best model will be saved before number of epochs reach this value\n",
        "\t\t\t\tself.learning_rate = 0.0001\n",
        "\t\t\t\tself.decay = 1e-6\n",
        "\t\t\t\tself.momentum = 0.9\n",
        "\n",
        "#load data\t\n",
        "x_tr,y_tr,x_t,y_t,x_val,y_val = loadData1d(xd_tr,yd_tr,xd_t,yd_t,xd_val,yd_val)\t\n",
        "\n",
        "print(x_tr.shape)\n",
        "print(x_val.shape)\n",
        "print(x_t.shape)\n",
        "\n",
        "args = arguments()\n",
        "\n",
        "#define model\n",
        "model = emo1d(input_shape=x_tr.shape[1:],num_classes=len(np.unique(np.argmax(y_tr, 1))),args=args)\n",
        "model.summary()\n",
        "\n",
        "#train model\n",
        "model = train(model,x_tr,y_tr,x_val,y_val,args=args)\n",
        "\n",
        "#test model\n",
        "score = test(model,x_t,y_t)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtR6hctiulme",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(x_t,y_t):\n",
        "\n",
        "\tsaved_model = model = load_model('./best_model_1D_CNN.h5')\n",
        "\tscore = saved_model.evaluate(x_t,y_t,batch_size=60)\n",
        "\tprint(score)\n",
        "\treturn score\n",
        "\n",
        "#test model\n",
        "print(\"Training\")\n",
        "score = test(x_tr,y_tr)\n",
        "print(\"Validation\")\n",
        "score = test(x_val,y_val)\n",
        "print(\"Testing\")\n",
        "score = test(x_t,y_t)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XAubA7ai4r5c"
      },
      "source": [
        "## 2D CNN and LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-F26wiVj4r5h",
        "colab": {}
      },
      "source": [
        "# 2D cnn for SER\n",
        "\n",
        "pw = 2 # Pool Layer Window size\n",
        "\n",
        "def emo2d(input_shape, num_classes,args):\n",
        "\t\n",
        "\tmodel = Sequential(name='Emo2D')\n",
        "\tprint(\"Hey\",input_shape)\n",
        "\t# LFLB1\n",
        "\tmodel.add(Conv2D(filters = 64,kernel_size = 3,strides=1,padding='same',data_format='channels_last',input_shape=input_shape, kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(Activation('elu'))\n",
        "\tmodel.add(MaxPooling2D(pool_size = (int(2*pw/2),int(2*pw/2)), strides = int(pw/2),data_format='channels_last'))\n",
        "\n",
        "\t#LFLB2\n",
        "\tmodel.add(Conv2D(filters=64, kernel_size = 3, strides=1,padding='same', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(Activation('elu'))\n",
        "\tmodel.add(MaxPooling2D(pool_size = (pw,pw), strides = pw,data_format='channels_last'))\n",
        "\n",
        "\t#LFLB3\n",
        "\tmodel.add(Conv2D(filters=128, kernel_size = 3, strides=1,padding='same', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(Activation('elu'))\n",
        "\tmodel.add(MaxPooling2D(pool_size = (pw,pw), strides = pw,data_format='channels_last',))\n",
        "\n",
        "\t# #LFLB4\n",
        "\tmodel.add(Conv2D(filters=128, kernel_size = 3, strides=1,padding='same', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(Activation('elu'))\n",
        "\tmodel.add(MaxPooling2D(pool_size = (pw,pw), strides = pw,data_format='channels_last'))\n",
        "\n",
        "\t# Reshape to feed it to LSTM\n",
        "\tmodel.add(Reshape((-1,1)))\n",
        "\n",
        "\t#LSTM\n",
        "\tmodel.add(LSTM(units=args.num_fc,return_sequences=False, kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
        "\t#FC\n",
        "\t# model.add(Dense(units=100,activation='relu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))) # increases the accuracy a little more than mentioned in the paper\n",
        "\n",
        "\tmodel.add(Dense(units=num_classes,activation='softmax'))\n",
        "\n",
        "\t#Model compilation\t\n",
        "\topt = optimizers.SGD(lr = args.learning_rate, decay=args.decay, momentum=args.momentum, nesterov=True)\n",
        "\tmodel.compile(optimizer=opt,loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\t\n",
        "\treturn model\n",
        "\n",
        "def train(model,x_tr,y_tr,x_val,y_val,args):\n",
        "\t\n",
        "\tes = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=30)\n",
        "\tmc = ModelCheckpoint('best_model_2D_CNN.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
        "\thistory = model.fit(x_tr,y_tr,epochs=args.num_epochs,batch_size=args.batch_size,validation_data=(x_val,y_val),callbacks=[es, mc])\n",
        "\treturn model\n",
        "\n",
        "def test(model,x_t,y_t):\n",
        "\n",
        "\tsaved_model = load_model('best_model_2D_CNN.h5')\n",
        "\tscore = saved_model.evaluate(x_t,y_t,batch_size=120)\n",
        "\tprint(score)\n",
        "\treturn score\n",
        "\n",
        "def loadData2d(xd_tr,yd_tr,xd_t,yd_t,xd_val,yd_val):\n",
        "\n",
        "\tx_tr = []\n",
        "\tx_val = []\n",
        "\tx_t = []\n",
        "\tsr = 16000\n",
        "\tfor a in xd_tr:\n",
        "\t\tS = librosa.feature.melspectrogram(y=a, sr=sr)\n",
        "\t\tx_tr.append(librosa.power_to_db(S, ref=np.max))\n",
        "\t\n",
        "\tfor a in xd_val:\n",
        "\t\tS = librosa.feature.melspectrogram(y=a, sr=sr)\n",
        "\t\tx_val.append(librosa.power_to_db(S, ref=np.max))\n",
        "\tfor a in xd_t:\n",
        "\t\tS = librosa.feature.melspectrogram(y=a, sr=sr)\n",
        "\t\tx_t.append(librosa.power_to_db(S, ref=np.max))\n",
        "\n",
        "\tx_tr,x_t,x_val = np.array(x_tr),np.array(x_t),np.array(x_val)\n",
        "\n",
        "\tx_tr = x_tr.reshape(-1,x_tr.shape[1],x_tr.shape[2],1)\n",
        "\tx_t = x_t.reshape(-1,x_t.shape[1],x_t.shape[2],1)\n",
        "\tx_val = x_val.reshape(-1,x_val.shape[1],x_val.shape[2],1)\n",
        "\ty_tr = to_categorical(yd_tr)\n",
        "\ty_t = to_categorical(yd_t)\n",
        "\ty_val = to_categorical(yd_val)\n",
        "\treturn np.array(x_tr),y_tr,np.array(x_t),y_t,np.array(x_val),y_val\n",
        "\n",
        "class arguments(object):        \n",
        "\t\tdef __init__(self):\n",
        "\t\t\t\tself.num_fc = 256\n",
        "\t\t\t\tself.batch_size = 5\n",
        "\t\t\t\tself.num_epochs = 1 #best model will be saved before number of epochs reach this value\n",
        "\t\t\t\tself.learning_rate = 1\n",
        "\t\t\t\tself.decay = 1e-6\n",
        "\t\t\t\tself.momentum = 0.9\n",
        "\n",
        "#load data\t\n",
        "x_tr,y_tr,x_t,y_t,x_val,y_val = loadData2d(xd_tr,yd_tr,xd_t,yd_t,xd_val,yd_val)\t\n",
        "\n",
        "print(x_tr.shape)\n",
        "print(x_val.shape)\n",
        "print(x_t.shape)\n",
        "\n",
        "args = arguments()\n",
        "\n",
        "#define model\n",
        "model = emo2d(input_shape=x_tr.shape[1:],num_classes=len(np.unique(np.argmax(y_tr, 1))),args=args)\n",
        "model.summary()\n",
        "\n",
        "# #train model\n",
        "model = train(model,x_tr,y_tr,x_val,y_val,args=args)\n",
        "\n",
        "# #test model\n",
        "score = test(model,x_t,y_t)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXzHhHM0N7wA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(model,x_t,y_t):\n",
        "\n",
        "\tsaved_model = load_model('./best_model_2D_CNN.h5')\n",
        "\tscore = saved_model.evaluate(x_t,y_t,batch_size=128)\n",
        "\tprint(score)\n",
        "\treturn score\n",
        "\n",
        "#test model\n",
        "print(\"Training\")\n",
        "score = test(model,x_tr,y_tr)\n",
        "print(\"Validation\")\n",
        "score = test(model,x_val,y_val)\n",
        "print(\"Testing\")\n",
        "score = test(model,x_t,y_t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77vFjwiRg1D5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = load_model('best_model_2D_CNN.h5')\n",
        "\n",
        "predict = np.argmax(np.array(model.predict(x_tr)),axis = 1)\n",
        "actual = np.array(yd_tr,dtype = np.dtype(np.int8))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(actual,predict))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}